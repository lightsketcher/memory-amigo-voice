<!doctype html>
<html>
<head>
<meta charset="utf-8">
<title>Memory Amigo — Voice Input</title>
<style>body{font-family:Arial;margin:18px}button{padding:10px;margin:6px}textarea{width:100%;height:100px}</style>
</head>
<body>
  <h1>Memory Amigo — Voice Input</h1>
  <div>
    <h3>Live (Browser Speech Recognition)</h3>
    <button id="startLive">Start Live</button>
    <button id="stopLive">Stop</button>
    <div><textarea id="liveTranscript" placeholder="Live transcript..."></textarea></div>
    <input id="live_categories" placeholder="categories e.g., consumption,learning" />
    <input id="live_mood" placeholder="mood e.g., inspired" />
    <button onclick="saveLive()">Save Live Transcript</button>
    <pre id="liveSave"></pre>
  </div>

  <hr>

  <div>
    <h3>Record (Recommended for ElevenLabs STT)</h3>
    <button id="record">Start Recording</button>
    <button id="stopRecord">Stop & Transcribe</button>
    <div><textarea id="recordedTranscript" placeholder="Recorded transcript appears here"></textarea></div>
    <input id="rec_categories" placeholder="categories" />
    <input id="rec_mood" placeholder="mood" />
    <button onclick="saveRecorded()">Save Recorded Transcript</button>
    <pre id="recResp"></pre>
  </div>

  <hr>

  <div>
    <h3>Search / Ask</h3>
    <input id="q" placeholder="Ask e.g., 'What movies inspired me this month?'" style="width:70%">
    <button onclick="search()">Search</button>
    <button onclick="ask()">Ask & Summarize</button>
    <pre id="searchRes"></pre>
  </div>

<script>
let recognition, recognizing=false;
if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
  const SR = window.SpeechRecognition || window.webkitSpeechRecognition;
  recognition = new SR();
  recognition.lang = 'en-US';
  recognition.interimResults = true;
  recognition.onresult = (e) => {
    let final='', interim='';
    for (let i=0;i<e.results.length;i++){
      const r = e.results[i];
      if (r.isFinal) final += r[0].transcript;
      else interim += r[0].transcript;
    }
    document.getElementById('liveTranscript').value = (final + ' ' + interim).trim();
  };
  recognition.onerror = console.error;
}
document.getElementById('startLive').onclick = () => { if (recognition && !recognizing){ recognition.start(); recognizing=true; document.getElementById('startLive').disabled=true; } };
document.getElementById('stopLive').onclick = () => { if (recognition && recognizing){ recognition.stop(); recognizing=false; document.getElementById('startLive').disabled=false; } };

async function saveLive(){
  const content = document.getElementById('liveTranscript').value;
  const categories = (document.getElementById('live_categories').value||'').split(',').map(s=>s.trim()).filter(Boolean);
  const mood = document.getElementById('live_mood').value || null;
  const payload = { title: content.slice(0,40), content, categories, tags:[], mood, date: new Date().toISOString() };
  const r = await fetch('/api/save',{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify(payload)});
  document.getElementById('liveSave').innerText = JSON.stringify(await r.json(), null, 2);
}

// Recording
let mediaRecorder, audioChunks=[];
document.getElementById('record').onclick = async () => {
  audioChunks=[];
  const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
  mediaRecorder = new MediaRecorder(stream);
  mediaRecorder.ondataavailable = e => audioChunks.push(e.data);
  mediaRecorder.start();
  document.getElementById('record').disabled = true;
  document.getElementById('stopRecord').disabled = false;
};
document.getElementById('stopRecord').onclick = async () => {
  mediaRecorder.stop();
  mediaRecorder.onstop = async () => {
    const blob = new Blob(audioChunks, { type:'audio/webm' });
    const fd = new FormData();
    fd.append('audio', blob, 'recording.webm');
    document.getElementById('recResp').innerText = 'Uploading...';
    const r = await fetch('/api/transcribe', { method:'POST', body: fd });
    const j = await r.json();
    if (j.ok) {
      document.getElementById('recordedTranscript').value = j.transcript;
      document.getElementById('recResp').innerText = 'Transcription done';
    } else {
      document.getElementById('recResp').innerText = 'Transcription failed: ' + JSON.stringify(j);
    }
    document.getElementById('record').disabled = false;
    document.getElementById('stopRecord').disabled = true;
  };
};

async function saveRecorded(){
  const content = document.getElementById('recordedTranscript').value;
  const categories = (document.getElementById('rec_categories').value||'').split(',').map(s=>s.trim()).filter(Boolean);
  const mood = document.getElementById('rec_mood').value || null;
  const payload = { title: content.slice(0,40), content, categories, tags:[], mood, date: new Date().toISOString() };
  const r = await fetch('/api/save',{method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify(payload)});
  document.getElementById('recResp').innerText = JSON.stringify(await r.json(), null, 2);
}

async function search(){
  const q = document.getElementById('q').value;
  const r = await fetch('/api/search?q='+encodeURIComponent(q));
  document.getElementById('searchRes').innerText = JSON.stringify(await r.json(), null, 2);
}

async function ask(){
  const q = document.getElementById('q').value;
  const r1 = await fetch('/api/recent');
  const recent = await r1.json();
  const items = (recent.result && recent.result.items) ? recent.result.items : (recent.result || []);
  const contexts = items.slice(0,8).map(e=> `${e.title||''}\n${e.content||''}\n${JSON.stringify(e.metadata||{})}`);
  const payload = { mode:'general', query: q, contextEntries: contexts };
  const r = await fetch('/api/infer',{method:'POST', headers:{'Content-Type':'application/json'}, body:JSON.stringify(payload)});
  document.getElementById('searchRes').innerText = JSON.stringify(await r.json(), null, 2);
}
</script>
</body>
</html>
